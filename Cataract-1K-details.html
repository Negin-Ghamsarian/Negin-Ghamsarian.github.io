<!DOCTYPE html>
<html lang="en">

<style>
.papertext{
    font-size: 28px;
  text-align: center;
}

.paperinfotext{
  text-align: center;
  font-size: 18px;
  color: #727477;
}

p {
    margin: 30px;
    margin-bottom:3cm
  }

p.big {
  line-height: 1.8;
  text-align:center;
}
p.small {
  line-height: 1.2;
  text-align:center;
}

#overflowTest {
  background: rgb(237, 237, 237);
  color: black;
  padding: 15px;
  width: 100%;
  height: 250px;
  overflow: scroll;
  border: 1px solid #ccc;
}

/* img {vertical-align: middle;
width: 250px;
background-color: white;
} */


</style>


<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <script src="https://kit.fontawesome.com/5233524c71.js" crossorigin="anonymous"></script>

  <title>Portfolio Details - iPortfolio Bootstrap Template</title>
  <meta content="" name="description">
  <meta content="" name="keywords">
  <script src="https://kit.fontawesome.com/a076d05399.js" crossorigin="anonymous"></script>

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

   <!-- Google Fonts -->
   <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">
   <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
   <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: iPortfolio
  * Updated: Jul 27 2023 with Bootstrap v5.3.1
  * Template URL: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Mobile nav toggle button ======= -->
  <i class="bi bi-list mobile-nav-toggle d-xl-none"></i>

  <!-- ======= Header ======= -->
  <header id="header">
    <div class="d-flex flex-column">

      <div class="profile">
        <img src="assets/img/profile-img.jpg" alt="" class="img-fluid rounded-circle">
        <h1 class="text-light"><a href="index.html">Negin Ghamsarian</a></h1>
        <div class="social-links mt-3 text-center">
          <a href="https://scholar.google.com/citations?user=stgToIMAAAAJ&hl=en" class="google scholar"><i class="ai ai-google-scholar ai-1x"></i></a>
          <a href="https://www.researchgate.net/profile/Negin-Ghamsarian" class="researchgate"><i class="ai ai-researchgate ai-1x"></i></a>
          <a href="https://orcid.org/0000-0002-0908-8972" class="orcid"><i class="ai ai-orcid ai-1x"></i></a>
          <a href="https://github.com/Negin-Ghamsarian" class="github"><i class="fa fa-github"></i></a>
          <a href="https://www.linkedin.com/in/negin-ghamsarian-a48462259/" class="linkedin"><i class="bx bxl-linkedin"></i></a>
        </div>
      </div>

      <nav id="navbar" class="nav-menu navbar">
        <ul>
          <li><a href="index.html#hero" class="nav-link scrollto active"><i class="bx bx-home"></i> <span>Home</span></a></li>
          <li><a href="index.html#about" class="nav-link scrollto"><i class="bx bx-user"></i> <span>About</span></a></li>
          <li><a href="index.html#news" class="nav-link scrollto"><i class="fa fa-newspaper-o"></i><span>News</span></a></li>
          <li><a href="index.html#Research" class="nav-link scrollto"><i class="fa-solid fa-magnifying-glass"></i><span>Fields of Research</span></a></li>
          <li><a href="index.html#education" class="nav-link scrollto"><i class="fas fa-graduation-cap"></i> <span>Education</span></a></li>  
          <li><a href="index.html#employement" class="nav-link scrollto"><i class="bx bx-book-content"></i> <span>Employement</span></a></li>
          <li><a href="index.html#teaching" class="nav-link scrollto"><i class="fa-solid fa-chalkboard-user"></i> <span>Teaching</span></a></li>
          <li><a href="index.html#skills" class="nav-link scrollto"><i class="fa-solid fa-code"></i> <span>Computer Skills</span></a></li>
          <li><a href="index.html#publications" class="nav-link scrollto"><i class="bx bx-server"></i> <span>Publications</span></a></li>
          <li><a href="index.html#Services" class="nav-link scrollto"><i class="fas fa-book-reader"></i> <span>Academic Services</span></a></li>
          <li><a href="index.html#Contact" class="nav-link scrollto"><i class="bx bx-envelope"></i> <span>Contact</span></a></li>
        </ul>
      </nav><!-- .nav-menu -->
    </div>
  </header><!-- End Header -->

  <main id="main">

    <!-- ======= Breadcrumbs ======= -->
    <section id="breadcrumbs" class="breadcrumbs">
      <div class="container">

        <div class="d-flex justify-content-between align-items-center">
          <h2></h2>
          <ol>
            <li><a href="index.html">Home</a></li>
            <li>Paper Details</li>
          </ol>
        </div>

      </div>
    </section><!-- End Breadcrumbs -->
    

    <!-- ======= Portfolio Details Section ======= -->
    <section id="portfolio-details" class="portfolio-details">
      <div class="container">
        <div class="papertext">
          <p class="big"><strong>Cataract-1K: Cataract Surgery Dataset for Scene Segmentation, Phase Recognition, and Irregularity Detection</strong></p>
        </div>
        <div class="papertext" style="font-size: 20px;">
          <p class="big">N. Ghamsarian<sup>1</sup>, Y. El-Shabrawi<sup>2</sup>, S. Nasirihaghighi<sup>3</sup>, D. Putzgruber-Adamitsch<sup>2</sup>, S. Wolf <sup>4</sup>, M. Zinkernagel<sup>4</sup>, K. Schoeffmann<sup>3</sup>, R. Sznitman<sup>1</sup></p>
        </div>
        <div class="paperinfotext">
          <p class="small"><sup>1</sup>Center for AI in Medicine, Faculty of Medicine, University of Bern, Bern, Switzerland</p>
          <p class="small"><sup>2</sup>Department of Ophthalmology, Klinikum Klagenfurt, Klagenfurt, Austria</p>
          <p class="small"><sup>3</sup>Department of Information Technology, Klagenfurt University, Klagenfurt, Austria</p>
          <p class="small"><sup>4</sup>Department of Ophthalmology, Inselspital, Bern, Switzerland</p>
          <img src="papers/nsd_logo.jpeg" class="center"> 
        </div>
        

        <p class="big">

        <div class="profile">
          <div class="social-links mt-5 text-center">
            <a href="https://arxiv.org/abs/2312.06295"><i class="fa fa-link" aria-hidden="true" style="font-size: 32px; padding: 10px;"></i></a>
            <a href="https://arxiv.org/abs/2312.06295"><i class="fa fa-file-pdf-o" aria-hidden="true" style="font-size: 32px; padding: 10px;"></i></a>
            <!-- <a href="#poster"><i class="fa fa-file-image-o" aria-hidden="true" style="font-size: 32px; padding: 10px;"></i></a>
            <a href="#video"><i class="fa fa-youtube-play" aria-hidden="true" style="font-size: 32px; padding: 10px;"></i></a> -->
            <a href="https://github.com/Negin-Ghamsarian/Cataract-1K"><i class="fa fa-github" aria-hidden="true" style="font-size: 32px;"></i></a>
            
          </div>
        </div>

      </p>

      

      <div class="section-title">
        <h2>Abstract</h2>
        
        In recent years, the landscape of computer-assisted interventions and post-operative surgical video analysis has been dramatically reshaped by deep-learning techniques, resulting in significant advancements in surgeons' skills, operation room management, and overall surgical outcomes. However, the progression of deep-learning-powered surgical technologies is profoundly reliant on large-scale datasets and annotations. In particular, surgical scene understanding and phase recognition stand as pivotal pillars within the realm of computer-assisted surgery and post-operative assessment of cataract surgery videos. In this context,  we present the largest cataract surgery video dataset that addresses diverse requisites for constructing computerized surgical workflow analysis and detecting post-operative irregularities in cataract surgery. We validate the quality of annotations by benchmarking the performance of several state-of-the-art neural network architectures for phase recognition and surgical scene segmentation. Besides, we initiate the research on domain adaptation for instrument segmentation in cataract surgery by evaluating cross-domain instrument segmentation performance in cataract surgery videos. The dataset and annotations are publicly available in Synapse.

      </div>

      <div class="section-title">
        <h2>Dataset Description</h2>

      <p>The <a href="https://arxiv.org/pdf/2312.06295.pdf">Cataract-1K</a> dataset consists of 1000 videos of cataract surgeries conducted in the eye clinic of Klinikum Klagenfurt from 2021 to 2023. The videos are recorded using a MediLive Trio Eye device mounted on a ZEISS OPMI Vario microscope. The Cataract-1K dataset comprises videos conducted by surgeons with a cumulative count of completed surgeries ranging from 1,000 to over 40,000 procedures. On average, the videos have a duration of 7.12 minutes, with a standard duration of 200 seconds. In addition to this large-scale dataset, we provide surgical phase annotations for 56 regular videos and relevant anatomical plus instrument pixel-level annotations for 2256 frames out of 30 cataract surgery videos. Furthermore, we provide a small subset of surgeries with two major irregularities, including &quot;pupil reaction&quot; and &quot;IOL rotation,&quot; to support further research on irregularity detection in cataract surgery. Except for the annotated videos and images, the remaining videos in the Cataract-1K dataset are encoded with a temporal resolution of 25 fps and a spatial resolution of 512 * 324.</p>

      <h3 id="phase-recognition-dataset">Phase recognition dataset</h3>
<p>A regular cataract surgery can include twelve action phases, including incision, viscoelastic, capsulorhexis, hydro-dissection, phacoemulsification, irrigation-aspiration, capsule polishing, lens implantation, lens positioning, viscoelastic-suction, anterior-chamber flushing, and tonifying/antibiotics. Besides, the idle phases refer to the time spans in the middle of a phase or between two phases when the surgeons mainly change the instruments and no instrument is visible inside the frames. </p>
<p>We provide a large annotated dataset to enable comprehensive studies on deep-learning-based phase recognition in cataract surgery videos. <strong>Table 1</strong> visualizes the phase annotations corresponding to 56 regular cataract surgery videos, with a spatial resolution of 1024 * 768, a temporal resolution of 30 fps, and an average duration of 6.45 minutes with a standard deviation of 2.04 minutes.  This dataset comprises patients with an average age of 75 years, ranging from 51 to 93 years, and a standard deviation of 8.69 years. The videos present in the phase recognition dataset correspond to surgeries executed by surgeons with an average experience of 8929 surgeries and a standard deviation of 6350 surgeries. Frame-level annotations for phase recognition are provided in CSV files, determining the first and the last frames for all action phases per video. The preprocessing codes to extract all action and idle phases from a video using the CSV files are provided in the GitHub repository of the paper. Furthermore, <strong>Figure 1</strong> demonstrates the total duration of the annotations corresponding to each phase from 56 videos.</p>

<br><figure>
  <figcaption><strong>Table 1.</strong> Visualizations of phase annotations for 56 normal cataract surgeries. The durations of the videos are different and normalized for better visualization.</figcaption>
  <img src="papers/Cataract-1K/imgs/Table1.png" alt=" Visualizations of phase annotations for 56 normal cataract surgeries. The durations of the videos are different and normalized for better visualization." width="900">
</figure>


<br><figure>
  <img src="papers/Cataract-1K/imgs/pie_chart.png" alt=" Total duration of the annotated phases in the 56 annotated cataract surgery videos (in seconds)." width = "600">
  <figcaption><strong>Figure 1.</strong> Total duration of the annotated phases in the 56 annotated cataract surgery videos (in seconds).</figcaption>
</figure>



<h3 id="semantic-segmentation-dataset">Semantic segmentation dataset</h3>

<br><figure>
  <img src="papers/Cataract-1K/imgs/Figure3.png" alt=" Visualization of pixel-based annotations corresponding to relevant anatomical structures and instruments in cataract surgery and the challenges associated with different objects." width="1000">
  <figcaption><strong>Figure 2</strong> visualizes pixel-level annotations for relevant anatomical objects and instruments.</figcaption>
</figure>


<br><p><strong>Figure 2.</strong> Visualization of pixel-based annotations corresponding to relevant anatomical structures and instruments in cataract surgery and the challenges associated with different objects.</p>
<p>The semantic segmentation dataset includes frames from 30 regular cataract surgery videos with a spatial resolution of $1024 \times 768$ and an average duration of 6.52 minutes with a standard deviation of two minutes. Frame extraction is performed at the rate of one frame per five seconds. Subsequently, the frames featuring very harsh motion blur or out-of-scene iris are excluded from the dataset. We provide pixel-level annotations for three relevant anatomical structures, including iris, pupil, and intraocular lens, as well as nine instruments used in regular cataract surgeries including slit/incision knife, gauge, spatula, capsulorhexis cystome, phacoemulsifier tip, irrigation-aspiration, lens injector, capsulorhexis forceps, and katana forceps. All annotations are performed using polygons in the <a href="https://supervisely.com/">Supervisely platform</a>, and exported as JSON files. Within this dataset, the included individuals possess an average age of 74.5 years, spanning from 51 to 90 years, with a standard deviation of 8.43 years. Additionally, the videos contained in the semantic segmentation dataset depict surgeries conducted by surgeons whose collective experience averages 8033 surgeries, with a standard deviation of 3894 surgeries. The provided dataset enables a reliable study of segmentation performance for relevant anatomical structures, binary instruments, and multi-class instruments. Pixel-level annotations are provided in two formats: (1) Supervisely format, for which we provide Python codes for mask creation from JSON files, and (2) COCO format, which also provides bounding box annotations for all pixel-level annotated objects. The latter annotations can be used for object localization problems. The preprocessing codes to create training masks for &quot;anatomy plus instrument segmentation&quot;, &quot;binary instrument segmentation&quot;, and &quot;multi-class instrument segmentation&quot; are provided in the GitHub repository of the paper. We have formed five folds with patient-wise separation, meaning every fold consists of the frames corresponding to six distinct videos. <strong>Table 2</strong> compares the number of instances and their appearance percentage in the frames. Besides, <strong>Table 3</strong> lists the average number of pixels per frame corresponding to each label.</p>


<br><figure>
  <figcaption><strong>Table 2.</strong> Number of instances and presence in the frames (% of total number of frames in each fold).</figcaption>
  <img src="papers/Cataract-1K/imgs/Table2.png" alt=" Number of instances and presence in the frames (% of the total number of frames in each fold)." width="900">
</figure>

<br><figure>
  <figcaption><strong>Table 3.</strong> Average pixels corresponding to different labels per frame.</figcaption>
  <img src="papers/Cataract-1K/imgs/Table3.png" alt="Average pixels corresponding to different labels per frame." width="900">
</figure>


<h3 id="irregularity-detection-dataset">Irregularity detection dataset</h3>
<p>This dataset contains two small subsets of major intra-operative irregularities in cataract surgery, including pupil reaction and lens rotation.</p>
<ul>
<li><strong>Pupil Contraction:</strong> During the phacoemulsification phase, where the occluded natural lens is corrupted and suctioned, the amount of light received by photoreceptors may suddenly increase. This increase in light reception affects the size of the pupil, usually resulting in slow (gradual) pupil contraction. In some cases, however, the pupil unexpectedly reacts to the lighting changes and becomes quickly contracted. These sudden reactions in pupil size can lead to serious intra-operative implications. Especially during the phacoemulsification phase where the instrument is deeply inserted inside the eye, sudden changes in pupil size may lead to injuries to the eye’s tender tissues. Besides, achieving precise IOL alignment or centration becomes challenging in cases where intraoperative pupil contraction (miosis) occurs. Particularly in multifocal IOLs, minor displacements or tilts, which might be negligible for conventional mono-focal IOLs, can significantly compromise visual performance. In the case of toric IOLs, precise alignment of the torus is crucial, as any deviation diminishes the IOL&#39;s effectiveness. Detection of unusual pupil reactions and severe pupil contractions during the surgery can highly contribute to the overall outcomes of cataract surgery and provide important insight for further post-operative investigations. Figure 4-top demonstrates an example of severe pupil contraction during cataract surgery.</li>
<li><strong>IOL rotation:</strong> Although aligned and centered upon surgery&#39;s conclusion, the IOL may rotate or dislocate following the surgery. Even slight deviations, such as minor misalignments of the torus in toric IOLs or the slight displacement and tilting of multifocal IOLs, can result in significant distortions in vision and leave patients dissatisfied. The sole way to address this postoperative complication is follow-up surgery, entailing added costs, heightened surgical risks, and patient discomfort. Identification of intra-operative indicators for predicting and preventing post-surgical IOL dislocation is an unmet clinical need. It is argued that intra-operative rotation of IOLs during cataract surgery is the leading cause of post-operative misalignments. Hence, automatic detection and measurement of intra-operative lens rotations can effectively contribute to preventing post-operative IOL dislocation. Figure 4-bottom represents fast clockwise rotations of IOL during unfolding, which occur in less than seven seconds.</li>
</ul>

<br><figure>
  <img src="papers/Cataract-1K/imgs/Figure4.png" alt="Intra-operative irregularities in cataract surgery." width="900">
  <figcaption><strong>Figure 3.</strong> Intra-operative irregularities in cataract surgery.</figcaption>
</figure>

<hr>
</div>


      <!-- <section id="video">

      <div class="section-title">
        <h2>Presentation</h2>
        
        <p class="big">

          <iframe width="890" height="500"  src="https://www.youtube.com/embed/XnCeeW6nTYM?si=HGmYiydI802G1dIp" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
        </p>

      </div>
    </section>


    <section id="poster">

      <div class="section-title">
        <h2>Poster</h2>       
        <p class="big">

          <object data="papers/Poster_Vertical_TI_ST_MICCAI23.pdf" type="application/pdf" width="100%" height="800px">
            <p>Unable to display PDF file. <a href="papers/Poster_Vertical_TI_ST_MICCAI23.pdf">Download</a> instead.</p>
          </object>

         </p>
      </div>
    </section>  -->
    
    <section>
      <div class="section-title">
        <h2>Citation</h2>
        
        
        <div id="overflowTest">
          @inproceedings{Cataract-1K, <br>
            author    = {Negin Ghamsarian and <br>
                        Yosuf El-Shabrawi and <br>
                        Sahar Nasirihaghighi and <br>
                        Doris Putzgruber-Adamitsch and <br>
                        Martin Zinkernagel and <br>
                        Sebastian Wolf and <br>
                        Klaus Schoeffmann and <br>
                        Raphael Sznitman}, <br>
            title     = {Cataract-1K: Cataract Surgery Dataset for Scene Segmentation, Phase Recognition, and Irregularity Detection (to appear)},
            
        }
            }

        </div>       
      </div>
    </section> 
        

        

      </div>
    </section><!-- End Portfolio Details Section -->

  </main><!-- End #main -->



  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/purecounter/purecounter_vanilla.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.umd.js"></script>
  <script src="assets/vendor/waypoints/noframework.waypoints.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>